---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.10.3
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

# Model Comparison

+++

To compare models, we will first optimize the parameters of two diffrent models and look at how the different parameters settings impact the model comparison.  Later, we'll see how to compare across models of different classes.  

```{code-cell} ipython3
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import pandas as pd
from sklearn import datasets
from sklearn import cluster
from sklearn import svm
from sklearn import tree
# import the whole model selection module
from sklearn import model_selection
sns.set_theme(palette='colorblind')
```

We'll use the iris data again. 

```{code-cell} ipython3
iris_X, iris_y = datasets.load_iris(return_X_y=True)
```

Remember, we need to split the data into training and test.  The cross validation step will hep us optimize the parameters, but we don't want *data leakage* where the model has seen the test data multiple times. So, we split the data here for train and test annd the cross validation splits the training data into train and "test" again, but this test is better termed validation. 

```{code-cell} ipython3
iris_X_train, iris_X_test, iris_y_train, iris_y_test = model_selection.train_test_split(
    iris_X,iris_y, test_size =.2)
```

Then we can make the object, the parameter grid dictionary and the Grid Search object.  We split these into separate cells, so that we can use the built in help to see more detail. 

```{code-cell} ipython3
dt = tree.DecisionTreeClassifier()
```

```{code-cell} ipython3
params_dt = {'criterion':['gini','entropy'],
             'max_depth':[2,3,4],
       'min_samples_leaf':list(range(2,20,2))}
```

```{code-cell} ipython3
dt_opt = model_selection.GridSearchCV(dt,params_dt)
```

Then we fit the Grid search using the training data, and remember this actually resets the parameters and then cross validates multiple times. 

```{code-cell} ipython3
dt_opt.fit(iris_X_train,iris_y_train)
```

adn look at the results

```{code-cell} ipython3
dt_opt.cv_results_
```

We can reformat it into a dataframe for further analysis. 

```{code-cell} ipython3
dt_df = pd.DataFrame(dt_opt.cv_results_)
dt_df.head(2)
```

```{admonition} Correction
The parameters in this function were in the wrong 
order in this function in class
```
I changed the markers and the color of the error bars for readability. 

```{code-cell} ipython3
plt.errorbar(x=dt_df['mean_fit_time'],y=dt_df['mean_score_time'],
     xerr=dt_df['std_fit_time'],yerr=dt_df['std_score_time'],
             marker='s',ecolor='r')
plt.xlabel('fit time')
plt.ylabel('score time')
# save the limits so we can reuse them
xmin, xmax, ymin, ymax = plt.axis()
```

The "points" are at the mean fit and score times. The lines are the "standard deviation" or how much we expect that number to vary, since means are an estimate. 
Because the data shows an upward trend, this plot tells us that mostly, the models that are slower to fit are also slower to apply. This makes sense for decision trees, deeper trees take longer to learn and longer to traverse when predicting. 
Because the error bars mostly overlap the other points, this tells us that mostly the variation in time is not a reliable difference. If we re-ran the GridSearch, we could get them in different orders. 

To interpret the error bar plot, let's look at a line plot of just the means, with the same limits so that it's easier to compare to the plot above. 

```{code-cell} ipython3
plt.plot(dt_df['mean_fit_time'],
            dt_df['mean_score_time'], marker='s')
plt.xlabel('fit time')
plt.ylabel('score time')
# match the axis limits to above
plt.ylim(ymin, ymax)
plt.xlim(xmin,xmax)
```

this plot shows the mean times, without the error bars. 

```{code-cell} ipython3
dt_df['mean_test_score'].plot(kind='bar')
```

```{code-cell} ipython3
dt_df['mean_test_score']
```

Now let's compare with a different model, we'll use the parameter optimized version for that model. 

```{code-cell} ipython3
svm_clf = svm.SVC()
param_grid = {'kernel':['linear','rbf'], 'C':[.5, 1, 10]}
svm_opt = GridSearchCV(svm_clf,param_grid,)
```

The error above is because we didn't import `GridSearchCV` directly today, we imported the whole `model_selection` module, so we have to use that in order to access the class. 

```{code-cell} ipython3
svm_clf = svm.SVC()
param_grid = {'kernel':['linear','rbf'], 'C':[.5, .75,1,2,5,7, 10]}
svm_opt = model_selection.GridSearchCV(svm_clf,param_grid,cv=10)
```

```{code-cell} ipython3
type(model_selection)
```

```{code-cell} ipython3
dt_opt.__dict__
```

This doesn't have attributes yet, even though they are the same type, because we have not fit it tot data yet. 

```{code-cell} ipython3
type(svm_opt), type(dt_opt)
```

Now we can fit the model to the training data of this second model. 

```{code-cell} ipython3
# fit the model and  put the CV results in a dataframe
svm_opt.fit(iris_X_train,iris_y_train)
sv_df = pd.DataFrame(svm_opt.cv_results_)
```

```{code-cell} ipython3
sv_df.head(2)
```

```{code-cell} ipython3
plt.errorbar(x=sv_df['mean_fit_time'],xerr=sv_df['std_fit_time'],
            y=sv_df['mean_score_time'],yerr=sv_df['std_score_time'])
```

```{code-cell} ipython3
sv_df.columns
```

We can see if the models that take longer to fit or score perform better.

```{code-cell} ipython3
svm_time = sv_df.melt(id_vars=['param_C', 'param_kernel', 'params',],
                      value_vars=['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time'])
sns.lmplot(data=sv_df, x='mean_fit_time',y='mean_test_score',
          hue='param_kernel',fit_reg=False)
```

This looks like mostly no. 

```{code-cell} ipython3
sns.lmplot(data=sv_df, x='mean_score_time',y='mean_test_score',
          hue='param_kernel',fit_reg=False)
```

Again, for score time, the slower models don't appear to be better.  Remember though the time differences weren't that different. 

```{admonition} Try it yourself
Try this same analysis for the decision tree, does it matter there?
```

```{code-cell} ipython3

sv_df_scores = sv_df.melt(id_vars=['param_C', 'param_kernel', 'params',],
                    value_vars=['split0_test_score',
       'split1_test_score', 'split2_test_score', 'split3_test_score',
       'split4_test_score'], value_name='score')
sv_df_scores.head()
```

```{code-cell} ipython3
sns.catplot(data=sv_df_scores,x='param_C',y='score',
            col='param_kernel')
```

```{admonition} Try it yourself
Try interpretting the plot above, what does it say? what can you conclude from it. 
```

```{code-cell} ipython3
dt_df['mean_test_score'].plot(kind='bar')
```

```{code-cell} ipython3
sv_df['mean_test_score'].plot(kind='bar')
```

From these last two plots we see that the SVM performance is more sensitive to its parameters, where for the parameters tested, the decision tree is not impacted. 

What can we say based on this?  We'll pick up from here on Wednesday.
