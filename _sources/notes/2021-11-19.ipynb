{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23384564",
   "metadata": {},
   "source": [
    "# Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315a175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn import cluster\n",
    "\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "# import the whole model selection module\n",
    "from sklearn import model_selection\n",
    "sns.set_theme(palette='colorblind')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ba3397",
   "metadata": {},
   "source": [
    "Today, we'll load a new dataset and use the default sklearn data structure for datasets.  We get back the default data stucture when we use a `load_` function without any parameters at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e24e3bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0a0a03",
   "metadata": {},
   "source": [
    "This shows us that the type is defined by sklearn and they called it `bunch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40b0b1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5b0225",
   "metadata": {},
   "source": [
    "We can print it out to begin exploring it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f1389d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd4555f",
   "metadata": {},
   "source": [
    "We note that it has key value pairs, and that the last one is called `DESCR` and is text that describes the data.  If we send that to the print function it will be formatted more readably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f4bbd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ba1c15",
   "metadata": {},
   "source": [
    "This tells us that we are going to be predicting what digit (0,1,2,3,4,5,6,7,8, or 9) is in the image.\n",
    "\n",
    "To get an idea of what the images look like, we can use `matshow` which is short for matrix show. It takes a 2D matrix and plots it as a grayscale image. To get the actual color bar, we use the matplotlib `plt.gray()`.  \n",
    "````{margin}\n",
    "```{admonition} Try it yourself\n",
    "Try using matshow without `plt.gray()`. How is it different?  What might alternatives do?  What other code in this notebook influences how plots look?\n",
    "```\n",
    "```{tip}\n",
    "Removing a line from an excerpt of code can help you see hat that line did and learn more about how each piece work.\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf006480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4a3419ca10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/home/runner/work/BrownFall21/BrownFall21/_build/jupyter_execute/notes/2021-11-19_11_2.png"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.matshow(digits.images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f6147",
   "metadata": {},
   "source": [
    "`bunch` objects are designed for machine learning, so they have the features as \"data\" and target explicitly identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ced2d378",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_X = digits.data\n",
    "digits_y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7ad440",
   "metadata": {},
   "source": [
    "We can further check the type and shape of these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15f78ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(digits_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e8d495",
   "metadata": {},
   "source": [
    "```{note}\n",
    "because this is the target, it's okay that this is one dimensional.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a5d3ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94ab3197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae380ea",
   "metadata": {},
   "source": [
    "This has one row for each sample and has reshaped the 8x8 image into a 64 length vector. So we have one 'feature' for each pixel in the images.\n",
    "\n",
    "We are going to do some model comparison, so we will instantiate estimator objects for two different classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b77c658",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = svm.SVC(gamma=0.001)\n",
    "gnb_clf = naive_bayes.GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d97b75",
   "metadata": {},
   "source": [
    "We're going to use a [ShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html) object to do Cross validation with 100 iterations to get smoother mean test and train\n",
    "score curves, each time with 20% data randomly selected as a validation set.\n",
    "\n",
    "```{admonition} Further Reading\n",
    "\n",
    "You can see visualization of different [cross validation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#visualize-cross-validation-indices-for-many-cv-objects) types in the sklearn documentation.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1d3d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = model_selection.ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109f554d",
   "metadata": {},
   "source": [
    "```{note}\n",
    "This object has a `random_state` object, the `GridSearchCV` that we were using didn't have a way to control the random state directly, but it accepts not only integers, but also cross validation objects to the `cv` parameter. The KFold cross validation object also has that parameter, so we could repeat what we did in previous classes by creating a `KFold` object with a fixed random state.\n",
    "```\n",
    "\n",
    "<!-- ```{code-cell} ipython3\n",
    "# this is why gridsearch cv doesn't have random state\n",
    "model_selection.KFold()\n",
    "``` -->\n",
    "\n",
    "We'll also create a linearly spaced list of training percentages and we'll also divide it into more jobs to be more computationally efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e093d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes=np.linspace(0.1, 1.0, 5)\n",
    "n_jobs=4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0211ae",
   "metadata": {},
   "source": [
    "```{admonition} Try it yourself\n",
    "Try varying the `n_jobs` parameter and tmiing the execution using the\n",
    "[timit magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-timeit)\n",
    "```\n",
    "\n",
    "Now we can create the learning curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "922f8fac",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2321/2321808296.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     return_times=True,)\n\u001b[0m",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mlearning_curve\u001b[0;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times, fit_params)\u001b[0m\n\u001b[1;32m   1567\u001b[0m                 \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_times\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m             )\n\u001b[0;32m-> 1569\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_test_proportions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1570\u001b[0m         )\n\u001b[1;32m   1571\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_aggregate_score_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_sizes_svm, train_scores_svm, test_scores_svm, fit_times_svm, score_times_svm = model_selection.learning_curve(\n",
    "    svm_clf,\n",
    "    digits_X,\n",
    "    digits_y,\n",
    "    cv=cv,\n",
    "    n_jobs=n_jobs,\n",
    "    train_sizes=train_sizes,\n",
    "    return_times=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13e8241",
   "metadata": {},
   "source": [
    "It returns the list of the counts for each training size (we input percentages and it returns counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1223dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2deb54",
   "metadata": {},
   "source": [
    "The other parameters, it returns a list for each length that's 100 long because our cross validation was 100 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212f6e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_times_svm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91bb892",
   "metadata": {},
   "source": [
    "We can save it in a DataFrame after averaging over the 100 trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18dacfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_learning_df = pd.DataFrame(data = train_sizes_svm, columns = ['train_size'])\n",
    "# svm_learning_df['train_size'] = train_sizes_svm\n",
    "svm_learning_df['train_score'] = np.mean(train_scores_svm,axis=1)\n",
    "svm_learning_df['test_score'] = np.mean(test_scores_svm,axis=1)\n",
    "svm_learning_df['fit_time'] = np.mean(fit_times_svm,axis=1)\n",
    "svm_learning_df['score_times'] = np.mean(score_times_svm,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bea94d8",
   "metadata": {},
   "source": [
    "then we can look at the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bad3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_learning_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27051e6",
   "metadata": {},
   "source": [
    "We can use our skills in transforming data to make it easier to exmine just a subset of the scores.\n",
    "````{margin}\n",
    "```{hint}\n",
    "This is *one* thing we can analyze, but there are others. To earn prepare on assignment 11,  manipulate your reuslts a different way.\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a335007",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_learning_df_scores = svm_learning_df.melt(id_vars=['train_size'],value_vars=['train_score','test_score'])\n",
    "\n",
    "svm_learning_df_scores.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398f5875",
   "metadata": {},
   "source": [
    "This new DataFrame allows us to make convenient plots.\n",
    "\n",
    "````{margin}\n",
    "```{tip}\n",
    "Getting used to thinking though these sorts of manipulations can take time, but\n",
    "is valuable. Investing time to learn these things will help you both write\n",
    "shorter, more readable, easy to examine, code (which is nicer to your co-workers)\n",
    "and help you develop flexible mental representation.  The flexiblity of your\n",
    "mental model of material is the way learning scientists distinguish compentent\n",
    "practioners from experts.  \n",
    "\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa28c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = svm_learning_df_scores, x ='train_size', y='value',hue='variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e0470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes_gnb, train_scores_gnb, test_scores_gnb, fit_times_gnb, score_times_gnb = model_selection.learning_curve(\n",
    "    gnb_clf,\n",
    "    digits_X,\n",
    "    digits_y,\n",
    "    cv=cv,\n",
    "    n_jobs=n_jobs,\n",
    "    train_sizes=train_sizes,\n",
    "    return_times=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2042e976",
   "metadata": {},
   "source": [
    "We can do the same for Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f3589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_learning_df = pd.DataFrame(data = train_sizes_gnb, columns = ['train_size'])\n",
    "# gnb_learning_df['train_size'] = train_sizes_gnb\n",
    "gnb_learning_df['train_score'] = np.mean(train_scores_gnb,axis=1)\n",
    "gnb_learning_df['test_score'] = np.mean(test_scores_gnb,axis=1)\n",
    "gnb_learning_df['fit_time'] = np.mean(fit_times_gnb,axis=1)\n",
    "gnb_learning_df['score_times_gnb'] = np.mean(score_times_gnb,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f866cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_learning_scores = gnb_learning_df.melt(id_vars=['train_size'],value_vars=['train_score','test_score'])\n",
    "sns.lineplot(data = gnb_learning_scores, x ='train_size', y='value',hue='variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60882a6c",
   "metadata": {},
   "source": [
    "````{margin}\n",
    "```{admonition} Question in Class\n",
    "This was a question after class, but the answer makes more sense inline here.\n",
    "```\n",
    "````\n",
    "These scores are overall not as high as the SVM (note the values on the y axis. )\n",
    "\n",
    "## Questions After Class\n",
    "\n",
    "\n",
    "### When would I use an SVM?\n",
    "\n",
    "```{toggle}\n",
    "SVMs are a very powerful model and they're good when you need relatively quick\n",
    "training (and test) time, a model that takes a small amount of memory (eg running\n",
    "  the prediction on a mobile device or smart device), with high accuracy.  \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "source_map": [
   12,
   16,
   30,
   34,
   36,
   40,
   42,
   46,
   48,
   52,
   54,
   68,
   71,
   75,
   78,
   82,
   84,
   90,
   94,
   96,
   102,
   105,
   115,
   117,
   130,
   133,
   141,
   150,
   153,
   155,
   158,
   160,
   163,
   170,
   173,
   175,
   184,
   188,
   204,
   208,
   217,
   221,
   230,
   233
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}