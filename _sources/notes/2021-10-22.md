---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.10.3
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

# Decision Tree Setting and more Evaluation
```{code-cell} ipython3
import pandas as pd
import seaborn as sns
from sklearn import tree
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
sns.set(palette ='colorblind') # this improves contrast

from sklearn.metrics import confusion_matrix, classification_report
```

## Review
```{code-cell} ipython3
corner_data = 'https://raw.githubusercontent.com/rhodyprog4ds/06-naive-bayes/f425ba121cc0c4dd8bcaa7ebb2ff0b40b0b03bff/data/dataset6.csv'
df6= pd.read_csv(corner_data,usecols=[1,2,3])
iris_df = sns.load_dataset('iris')
```

```{code-cell} ipython3
df6.columns
```
set up the same splits again
```{code-cell} ipython3
X_train, X_test, y_train, y_test = train_test_split(df6[['x0','x1']],
                                                   df6['char'],
                                                    random_state=34)
```

Fit a baseline model with default settings

```{code-cell} ipython3
dt = tree.DecisionTreeClassifier()
dt.fit(X_train,y_train)
dt.score(X_test,y_test)
```

it does well, but let's examine it more closely. First, we'll look back at the data.

```{code-cell} ipython3
g = sns.JointGrid(data=df6, x='x0', y ='x1', hue='char')
g.plot_joint(sns.scatterplot)
g.plot_marginals(sns.kdeplot)
g.refline(x=4, y=4)
```
In this, the dashed lines represent boundaries that separate the two classes.
Next, we can look at what it learned. Using `filled=True` makes the nodes shaded, so we can examine it better.

```{code-cell} ipython3
plt.figure(figsize=(15,20))
tree.plot_tree(dt,filled=True)
```

Each node in the tree shows the threshold that wa compared, the gini score and the number of samples from each class from the training data that pass through that node.

we can see from the graph what happened, but this is still not finding what we know would be the best performing decision tree.

Let's try limiting when it can split based on the share of the data.

```{code-cell} ipython3
dt_large_split = tree.DecisionTreeClassifier(min_samples_split=.2,
                                             max_depth=2)
dt_large_split.fit(X_train,y_train)
dt_large_split.score(X_test,y_test)
```

```{code-cell} ipython3
plt.figure(figsize=(15,20))
tree.plot_tree(dt_large_split,filled=True);
```


```{code-cell} ipython3
dt_large_split = tree.DecisionTreeClassifier(min_samples_split=.4,
                                             max_depth=2)
dt_large_split.fit(X_train,y_train)
dt_large_split.score(X_test,y_test)
```

We can also limit based on how much data has to be in each leaf.

```{code-cell} ipython3
dt_large_leaf = tree.DecisionTreeClassifier(min_samples_leaf=.2)
dt_large_leaf.fit(X_train,y_train)
dt_large_leaf.score(X_test,y_test)
```

```{code-cell} ipython3
plt.figure(figsize=(12,12))
tree.plot_tree(dt_large_leaf,filled=True);
```

This one gets the right number of levels, but still does not have good performance.

## More evaluation

To do more detailed evaluation than the main score, we have to get the predictions.

```{code-cell} ipython3
y_pred_ll = dt_large_leaf.predict(X_test)
print(classification_report(y_test,y_pred_ll))
```

We can also get the confusion matrix out
```{code-cell} ipython3
confusion_matrix(y_test,y_pred_ll)
```

We can unpack those values into individual elements, that match the [true negative, false positive, false negative, true positive labels](https://en.wikipedia.org/wiki/Confusion_matrix) using [ravel](https://numpy.org/doc/stable/reference/generated/numpy.ravel.html) flattens a 2d numpy array; defaul is 'C' row major order; can change with order param

```{code-cell} ipython3
tn, fp, fn, tp = confusion_matrix(y_test,y_pred_ll).ravel()
```

We can compute other metrics from the confusion matrix:

````{margin}
```{admonition} Further Reading

More on confusion matrices, use both to match up and figure out how you can calculate other metrics from these.
- [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)
- [wiki](https://en.wikipedia.org/wiki/Confusion_matrix)
```
````

Accuruacy is the true ones/ total number of samples

```{code-cell} ipython3
(tp + tn)/(tp+fp+fn+tn)
```


## Parsing Assignment 7

What does data good for classification look like?

- there has to be a categorical variable to be the target
- there has to be other variables as the features where it makes sense to predict the target from those variables

Datasets for Machine Learning: the [UCI repository](https://archive.ics.uci.edu/ml/index.php)

The new [beta](https://archive-beta.ics.uci.edu/) has a nicer interface for finding data.

You can filter by task and type of data. So far, we've only worked with tabular data and studied classification.

![a screenshot of the UCI Repo beta settings page, with Data Characteristics set to Tabular and Associated Tasks set to classification](../img/uci_settings_a7.png)

## Questions after class

### Is there some kind of rule of thumb to make it go faster?
```{toggle}
Not exactly.  The more you understand the models you'll build intutition that helpd you decide faster and there are ways to use search algorithm to find the best set of parameters.  We'll see those in a couple of weeks.  For now, try a little experimentation and we'll consider more then.
```


## More Practice

1. Write a function that uses if, else to implement the predict function of a decision tree
1. Compute the metrics from the confusion matrix (accuracy, precision, recall)
1. Apply Decision tree to the iris data


<!-- Precision is the percent of the positive predicted (in this case positive is predicted B)

```{code-cell} ipython3
:tags: ["hide"]
tp/(tp+fp)
```

```{code-cell} ipython3
tp/(tp+fn)
```

The precision and recall of the other class use the true negatives as the numerator

```{code-cell} ipython3
tn/(tn+fn), tn/(tn+fp)
``` -->
