{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ca5c679",
   "metadata": {},
   "source": [
    "# ML Task Review and Cross Validation\n",
    "\n",
    "## Relationship between Tasks\n",
    "\n",
    "We learned classification first, because it shares similarities with each\n",
    "regression and clustering, while regression and clustering have less in common.\n",
    "\n",
    "Classification is supervised learning for a categorical target.  \n",
    "Regression is supervised learning for a continuous target.\n",
    "Clustering is unsupervised learning for a categorical target.\n",
    "\n",
    "\n",
    "Sklearn provides a nice flow chart for thinking through this.  \n",
    "\n",
    "![estimator flow chart](https://scikit-learn.org/stable/_static/ml_map.png)\n",
    "\n",
    "Predicting a category is another way of saying categorical target. Predicting a\n",
    "quantitiy is another way of saying continuous target. Having lables or not is\n",
    "the difference between\n",
    "\n",
    "\n",
    "The flowchart assumes you know what you want to do with data and that is the\n",
    "ideal scenario. You have a dataset and you have a goal.\n",
    "For the purpose of getting to practice with a variety of things, in this course\n",
    "we ask you to start with a task and then find a dataset. Assignment 9 is the\n",
    "last time that's true however. Starting with Assignment 10 and the last\n",
    "portflios, you can choose and focus on a specific application domain and then\n",
    "choose the right task from there.  \n",
    "\n",
    "\n",
    "Thinking about this, however, you use this information to move between the tasks\n",
    "within a given type of data.\n",
    "For example, you can use the same data for clustering as you did for classification.\n",
    "Switching the task changes the questions though: classification evaluation tells\n",
    "us how separable the classes are given that classifiers decision rule. Clustering\n",
    "can find other subgroups or the same ones, so the evaluation we choose allows us\n",
    "to explore this in more ways.\n",
    "\n",
    "Regression requires a continuous target, so we need a dataset to be suitable for\n",
    "that, we can't transform from the classification dataset to a regression one.  \n",
    "However, we can go the other way and that's how some classification datasets are\n",
    "created.\n",
    "\n",
    "The UCI [adult](https://archive.ics.uci.edu/ml/datasets/adult) Dataset is a popular ML dataset that was dervied from census\n",
    "data. The goal is to use a variety of features to predict if a person makes\n",
    "more than $50k per year or not. While income is a continuous value, they applied\n",
    "a threshold ($50k) to it to make a binary variable. The dataset does not include\n",
    "income in dollars, only the binary indicator.  \n",
    "\n",
    "\n",
    "```{admonition} Further Reading\n",
    "Recent work reconsturcted the dataset with the continuous valued income.\n",
    "Their [repository](https://github.com/zykls/folktables) contains the data as well\n",
    "as links to their paper and a video of their talk on it.\n",
    "```\n",
    "\n",
    "## Cross Validation\n",
    "\n",
    "This week our goal is to learn how to optmize models. The first step in that is\n",
    "to get a good estimate of its performance.  \n",
    "\n",
    "We have seen that the test train splits, which are random, influence the\n",
    "performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a7aef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48eadd6",
   "metadata": {},
   "source": [
    "We'll use the Iris data with a decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "145016ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = sns.load_dataset('iris')\n",
    "\n",
    "iris_X = iris_df.drop(columns=['species'])\n",
    "iris_y = iris_df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454d7042",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt =tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e13e3d",
   "metadata": {},
   "source": [
    "We can split the data, fit the model, then compute a score, but since the\n",
    "splitting is a randomized step, the score is a random variable.\n",
    "\n",
    "For example, if we have a coin that we want to see if it's fair or not. We would\n",
    "flip it to test.  One flip doesn't tell us, but if we flip it a few times, we\n",
    "can estimate the probability it is heads by counting how many of the flips are\n",
    "heads and dividing by how many flips.  \n",
    "\n",
    "We can do something similar with our model performance. We can split the data\n",
    "a bunch of times and compute the score each time.\n",
    "\n",
    "`cross_val_score` does this all for us.\n",
    "\n",
    "It takes an estimator object and the data.\n",
    "\n",
    "By default it uses 5-fold cross validation. It splits the data into 5 sections,\n",
    "then uses 4 of them to train and one to test. It then iterates through so that\n",
    "each section gets used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c761458d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 0.96666667, 0.9       , 0.93333333, 1.        ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(dt,iris_X,iris_y,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0d5597",
   "metadata": {},
   "source": [
    "We get back a score for each section or \"fold\" of the data. We can average those\n",
    "to get a single estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d5608c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666668"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(dt,iris_X,iris_y,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88261644",
   "metadata": {},
   "source": [
    "We can use more folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17454fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.93333333, 1.        , 0.93333333, 0.93333333,\n",
       "       0.86666667, 0.93333333, 0.93333333, 1.        , 1.        ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(dt,iris_X,iris_y,cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342bd3a6",
   "metadata": {},
   "source": [
    "```{admonition} Try it yourself\n",
    "What is the equivalent `train_size` for 5 fold? what about 10-fold?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "053ef8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(dt,iris_X,iris_y,cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89f24bc",
   "metadata": {},
   "source": [
    "We can use *any* estimator object here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02737271",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46147f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -9.062     , -14.93195873, -18.93234207, -23.70894258,\n",
       "       -19.55457726])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(km,iris_X,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e653b3f",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "1. Assignments 9 assesses up to level 2 for classification\n",
    "1. Heads up: Assignment 10 and 11 ask you to explore your work from 2 of (7,8,9) by optimizing the parameter and comparing different models for the same task.  So\n",
    "the dataset selection problem is going away, little by little."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "source_map": [
   12,
   77,
   86,
   89,
   96,
   98,
   119,
   121,
   126,
   128,
   132,
   134,
   140,
   142,
   145,
   149,
   151
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}