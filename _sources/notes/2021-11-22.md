---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.10.3
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

# Intro to NLP- representing text data

```{code-cell} ipython3
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import euclidean_distances
import pandas as pd
```

```{code-cell} ipython3
# %load http://drsmb.co/310read

# add an entry to the following dictionary with a name as the key and a sentence as the value
# share a sentence about how you're doing this week
# remember this will be python code, don't use
# You can remain anonymous (this page & the notes will be fully public)
# by attributing it to a celebrity or psuedonym, but include *some* sort of attribution
sentence_dict = {
'Professor Brown':"I'm excited for Thanksgiving.",
'Matt Langton':"I'm doing pretty good, I'll be taking the days off to catch up on various classwork.",
'Evan':"I'm just here so my grade doesn't get fined",
'Greg Bassett':"I'm doing well, my birthday is today. I'm looking forward to seeing my family this Thursday, I haven't seen a lot of them in a long time.",
'Noah N':"I'm doing well! I can't wait to take opportuity of this long weekend to catch up on various HW's, projects, etc.",
'Tuyetlinh':"I'm struggling to get all my work done before break, but I'm excited to have that time off when I'm all done.",
'Kenza Bouabdallah':"I am doing good. How are you ?",
'Chris Kerfoot':"I'm doing pretty good. I'm happy to have some days off this week because of Thanksgiving!",
'Kang Liu': "New week, new start",
'Aiden Hill':"I am very much enjoying this class.",
'Muhammad S':"I am doing pretty well. I am looking forward to taking a few days off.",
'Max Mastrorocco':"Cannot wait for a break.",
'Daniel':"I am doing well. I am ready and excited for break!",
'Nate':"I'm just vibing right now, ready for break ",
'Jacob':"I am going to eat Turkey.",
'Anon':"nom nom nom"
}
```

## Terms


document: unit of text we’re analyzing (one sample)



token: sequence of characters in some particular document that are grouped together as a useful semantic unit for processing (basically a word)



stop words: no meaning, we don’t need them (like a, the, an,). Note that this is context dependent



dicationary: all of the possible words that a given system knows how to process

```{code-cell} ipython3
s1 = sentence_dict['Professor Brown']
```

```{code-cell} ipython3
s1
```

```{code-cell} ipython3
counts = CountVectorizer()
```

```{code-cell} ipython3
counts.fit_transform([s1])
```

```{code-cell} ipython3
counts.fit_transform([s1]).toarray()
```

```{code-cell} ipython3
counts.vocabulary_
```

```{code-cell} ipython3
s2 = sentence_dict['Kang Liu']
```

```{code-cell} ipython3
s2
```

```{code-cell} ipython3
counts.fit_transform([s1,s2])
counts.vocabulary_
```

```{code-cell} ipython3
counts.fit_transform([s1,s2]).toarray()
```

```{code-cell} ipython3
mat = counts.fit_transform(sentence_dict.values()).toarray()
```

```{code-cell} ipython3
mat
```

```{code-cell} ipython3
counts.get_feature_names()
```

```{code-cell} ipython3
sentence_df = pd.DataFrame(data = mat, columns =counts.get_feature_names(),
                          index=sentence_dict.keys())
```

```{code-cell} ipython3
sentence_df
```

```{code-cell} ipython3
sentence_df.max()
```

```{code-cell} ipython3
sentence_df.sum().max()
```

```{code-cell} ipython3
sentence_df.sum().idxmax()
```

```{code-cell} ipython3
sentence_df.sum().index
```

```{code-cell} ipython3
euclidean_distances(sentence_df)
```

```{code-cell} ipython3
dist_df = pd.DataFrame(data = euclidean_distances(sentence_df),
            index= sentence_dict.keys(), columns= sentence_dict.keys())
dist_df
```

WHo wrote the most similar question to me?

```{code-cell} ipython3
dist_df['Professor Brown'].drop('Professor Brown').idxmin()
```

```{code-cell} ipython3

```
