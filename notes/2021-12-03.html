
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>33. Predicting with Neural Networks &#8212; Programming for Data Science at URI Fall 2021</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/course_admonitions.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="34. Review, IDEA, &amp; Preparing for Deep Learning" href="2021-12-06.html" />
    <link rel="prev" title="32. Neural Networks" href="2021-12-01.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/310_2021.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Programming for Data Science at URI Fall 2021</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    About this Book
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Syllabus
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../syllabus/about.html">
   Basic Facts
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../syllabus/tools.html">
   Tools and Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../syllabus/achievements.html">
   Data Science Achievements
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../syllabus/grading.html">
   Grading
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../syllabus/policies.html">
   Grading Policies
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../syllabus/uri_resources.html">
   Support
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../syllabus/uri_statements.html">
   General URI Policies
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../syllabus/communication.html">
   Course Communications
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Notes
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="2021-09-08.html">
   1. Welcome to Programming to Data Science
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-09-10.html">
   2. Jupyter Notebook Tour &amp; Python Review
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-09-13.html">
   3. Getting help, object inspection, loading data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-09-15.html">
   4. Pandas DataFrames
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-09-17.html">
   5. More Loading Data, Indexing, and Iterables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-09-20.html">
   6. Exploratory Data Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-09-22.html">
   7. Visualization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-09-24.html">
   8. Exploratory Data Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-09-27.html">
   9. Reshaping Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-09-29.html">
   10. More Reshaping
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-10-01.html">
   11. Missing Data and Inconsistent coding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-10-04.html">
   12. Building Datasets From multiple Sources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-10-06.html">
   13. Reviewing Merges &amp; Databases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-10-08.html">
   14. Web Scraping
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-10-13.html">
   15. Intro to Machine learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-10-15.html">
   16. Interpetting and Evaluating Naive Bayes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-10-18.html">
   17. Making Predictions in Generative Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-10-20.html">
   18. Midsemester feedback and Decision Trees
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-10-22.html">
   19. Decision Tree Setting and more Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-10-25.html">
   20. Linear Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-10-29.html">
   21. Interpretting Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-11-01.html">
   22. Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-11-03.html">
   23. Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-11-05.html">
   24. Evaluating Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-11-08.html">
   25. ML Task Review and Cross Validation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-11-12.html">
   26. SVM and Parameter Optimizing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-11-15.html">
   27. Model Comparison
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-11-17.html">
   28. Model Selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-11-19.html">
   29. Learning Curves
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-11-22.html">
   30. Intro to NLP- representing text data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-11-29.html">
   31. More NLP &amp; Solving problems with ML
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-12-01.html">
   32. Neural Networks
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   33. Predicting with Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-12-06.html">
   34. Review, IDEA, &amp; Preparing for Deep Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-12-08.html">
   35. Neural Networks with Keras
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021-12-10.html">
   36. Convolutional Neural Netowrks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Assignments
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../assignments/01-python-syllabus.html">
   1. Portfolio Setup, Data Science, and Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../assignments/02-python-access.html">
   2. Practicing Python and Accessing Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../assignments/03-eda.html">
   3. Assignment 3: Exploratory Data Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../assignments/04-prepare.html">
   4. Assignment 4:
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../assignments/05-construct.html">
   5. Assignment 5: Constructing Datasets and Using Databases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../assignments/06-classification.html">
   6. Assignment 6: Understanding Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../assignments/07-decision-tree.html">
   7. Assignment 7: Decision Trees
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../assignments/08-regression.html">
   8. Assignment 8: Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../assignments/09-clustering.html">
   9. Assignment 9: Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../assignments/10-optimize.html">
   10. Assignment 10: Tuning Model Parameters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../assignments/11-compare.html">
   11. Assignment 11: Model Comparison
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../assignments/12-fake-news.html">
   12. Assignment 12: Fake News
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Portfolio
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../portfolio/index.html">
   Portfolio Dates and Key Facts
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../portfolio/intro_reflection.html">
   Submission Introductions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../portfolio/formatting.html">
   Formatting Tips
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../portfolio/check1ideas.html">
   Portfolio Check 1 Ideas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../portfolio/check2ideas.html">
   Check 2 Ideas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../portfolio/check4ideas.html">
   Check 4 Ideas
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  FAQ
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../faq/index.html">
   FAQ
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../faq/syllabus.html">
   Syllabus and Grading FAQ
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../faq/github.html">
   Git and GitHub
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../faq/debugging.html">
   Code Errors
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../resources/glossary.html">
   Glossary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../resources/python.html">
   References on Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../resources/cheatsheet.html">
   Cheatsheet
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../resources/datasets.html">
   Data Sources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../resources/tips.html">
   General Tips and Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../resources/learning.html">
   How to Study in this class
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../resources/gettinghelp.html">
   Getting Help with Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../resources/terminal.html">
   Terminals and Environments
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../resources/organization.html">
   Getting Organized for class
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://rhodyprog4ds.github.io/BrownFall20/letters/">
   Advice from FA2020 Students
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../letters/index.html">
   Letters to Future students
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/rhodyprog4ds/BrownFall21/main?urlpath=tree/notes/2021-12-03.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/rhodyprog4ds/BrownFall21/"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/rhodyprog4ds/BrownFall21//issues/new?title=Issue%20on%20page%20%2Fnotes/2021-12-03.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/rhodyprog4ds/BrownFall21/edit/main/notes/2021-12-03.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/notes/2021-12-03.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download notebook file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        <a href="../_sources/notes/2021-12-03.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reconstructing-the-predict-method">
   33.1. Reconstructing the Predict method
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#more-features-and-more-hidden-neurons">
   33.2. More Features and More Hidden Neurons
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optional-what-is-a-numerical-optimiztion-algorithm">
   33.3. (optional) What is a numerical optimiztion algorithm?
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Predicting with Neural Networks</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reconstructing-the-predict-method">
   33.1. Reconstructing the Predict method
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#more-features-and-more-hidden-neurons">
   33.2. More Features and More Hidden Neurons
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optional-what-is-a-numerical-optimiztion-algorithm">
   33.3. (optional) What is a numerical optimiztion algorithm?
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="predicting-with-neural-networks">
<h1><span class="section-number">33. </span>Predicting with Neural Networks<a class="headerlink" href="#predicting-with-neural-networks" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">expit</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">sklearn</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">model_selection</span>
<span class="c1"># from skearn.model_selection import train_test_split</span>

<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_theme</span><span class="p">(</span><span class="n">palette</span><span class="o">=</span><span class="s1">&#39;colorblind&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Today, were going to use <em>very</em> simple data in order to examin how a neural
network works.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
                          <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">hue</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:&gt;
</pre></div>
</div>
<img alt="../_images/2021-12-03_3_1.png" src="../_images/2021-12-03_3_1.png" />
</div>
</div>
<p>First, we’ll train and score a tiny neural net: with 1 hidden layer of 1 neuron.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>This is actually eqiuvalent to another classifier, called logistic Regression</p>
</div>
<div class="admonition-correction admonition">
<p class="admonition-title">Correction</p>
<p>I’ve removed the parameter <code class="docutils literal notranslate"><span class="pre">learning_rate_init=0.1</span></code> and <code class="docutils literal notranslate"><span class="pre">random_state=1</span></code>
because sklearn actually only
uses the learning rate and randomizaiont for some of the optimization algorithms:
adam and sgd, which we are not using.</p>
<p>These algorithms are good in high dimensional problems, our problem is simple,
so we don’t need the advnaced parameters or algorithms.</p>
</div>
</aside>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span>
  <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="c1"># 1 hidden layer, 1 aritficial neuron</span>
  <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="c1"># maximum 100 interations in optimization</span>
  <span class="n">alpha</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="c1"># regularization</span>
  <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;lbfgs&quot;</span><span class="p">,</span> <span class="c1">#optimization algorithm  </span>
  <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="c1"># how much detail to print</span>
  <span class="n">activation</span><span class="o">=</span> <span class="s1">&#39;identity&#39;</span> <span class="c1"># how to transform the hidden layer beofore passing it to the next layer</span>
<span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RUNNING THE L-BFGS-B CODE

           * * *

Machine precision = 2.220D-16
 N =            5     M =           10

At X0         0 variables are exactly at the bounds

At iterate    0    f=  2.34381D+00    |proj g|=  1.10750D+00

At iterate    1    f=  1.15884D+00    |proj g|=  5.22275D-01

At iterate    2    f=  7.01374D-01    |proj g|=  9.09004D-02

At iterate    3    f=  6.76700D-01    |proj g|=  9.43005D-02

At iterate    4    f=  1.73953D-01    |proj g|=  3.30244D-01

At iterate    5    f=  5.13513D-02    |proj g|=  2.94368D-02

At iterate    6    f=  4.99313D-02    |proj g|=  1.89818D-02

At iterate    7    f=  4.87264D-02    |proj g|=  5.76625D-03

At iterate    8    f=  4.86119D-02    |proj g|=  4.00697D-03

At iterate    9    f=  4.84878D-02    |proj g|=  1.92688D-03

At iterate   10    f=  4.83939D-02    |proj g|=  1.64081D-03

At iterate   11    f=  4.82015D-02    |proj g|=  3.84407D-03

At iterate   12    f=  4.80076D-02    |proj g|=  3.82976D-03

At iterate   13    f=  4.79248D-02    |proj g|=  9.15466D-04

At iterate   14    f=  4.79198D-02    |proj g|=  2.37753D-04

At iterate   15    f=  4.79196D-02    |proj g|=  5.87358D-05

           * * *

Tit   = total number of iterations
Tnf   = total number of function evaluations
Tnint = total number of segments explored during Cauchy searches
Skip  = number of BFGS updates skipped
Nact  = number of active bounds at final generalized Cauchy point
Projg = norm of the final projected gradient
F     = final function value

           * * *

   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F
    5     15     18      1     0     0   5.874D-05   4.792D-02
  F =   4.7919620535136993E-002

CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_&lt;=_PGTOL            
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> This problem is unconstrained.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
</div>
</div>
<p>Now we can see that it actually has another activation, that we didn’t change
the output layer still has a logistic activation layer, which we want.  If we
didn’t then the output layer wouldn’t be able to be interpretted as a probability,
because probability always needs to be between 0 and 1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">out_activation_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;logistic&#39;
</pre></div>
</div>
</div>
</div>
<p>The logistic function looks like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_logistic</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">y_logistic</span> <span class="o">=</span> <span class="n">expit</span><span class="p">(</span><span class="n">x_logistic</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_logistic</span><span class="p">,</span><span class="n">y_logistic</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;matplotlib.lines.Line2D at 0x7f49d5ab9760&gt;]
</pre></div>
</div>
<img alt="../_images/2021-12-03_9_1.png" src="../_images/2021-12-03_9_1.png" />
</div>
</div>
<p>The fit method learned the following weights:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">coefs_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[array([[-6.85186628],
        [ 0.19720034]]),
 array([[-1.91807161]])]
</pre></div>
</div>
</div>
</div>
<p>and biases</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">intercepts_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[array([0.02652099]), array([5.74570119])]
</pre></div>
</div>
</div>
</div>
<p>These are called coefficients and intercepts because the weights are mutliplied
by the inputs and the biases you can interpret as geometrically as shifting things,
like a line intercept (recall y=mx+b)</p>
<section id="reconstructing-the-predict-method">
<h2><span class="section-number">33.1. </span>Reconstructing the Predict method<a class="headerlink" href="#reconstructing-the-predict-method" title="Permalink to this headline">#</a></h2>
<p>we’ll use an acutally new point, we can make one up</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>list
</pre></div>
</div>
</div>
</div>
<p>we want a numpy array so we will cast it</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">pt</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>numpy.ndarray
</pre></div>
</div>
</div>
</div>
<p>numpy’s <code class="docutils literal notranslate"><span class="pre">matmul</span></code> does matrix multiplicaion (multiply columns by rows element wise and sum)</p>
<div class="math notranslate nohighlight">
\[f(x) = W_2g(W_1^T x +b_1) + b_2 \]</div>
<p>the <span class="math notranslate nohighlight">\(g\)</span> is the activation function, which we set to identity <span class="math notranslate nohighlight">\(g(x) = x\)</span> so we don’t have to do more</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">pt</span><span class="p">,</span><span class="n">clf</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">clf</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">*</span><span class="n">clf</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">clf</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>  <span class="n">Input</span> <span class="n">In</span> <span class="p">[</span><span class="mi">11</span><span class="p">]</span>
    <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">pt</span><span class="p">,</span><span class="n">clf</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">clf</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">*</span><span class="n">clf</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">clf</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                                                    <span class="o">^</span>
<span class="ne">SyntaxError</span>: unmatched &#39;)&#39;
</pre></div>
</div>
</div>
</div>
<p>but we’re not quite done, the output layer still transforms using the logistic
function, which is also known as <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.expit.html"><code class="docutils literal notranslate"><span class="pre">expit</span></code></a> and we have imported from scipy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">expit</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">pt</span><span class="p">,</span><span class="n">clf</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">clf</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">*</span><span class="n">clf</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">clf</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.00027347]])
</pre></div>
</div>
</div>
</div>
<p>We can compare this to the classifier’s output. It outputs a probability for
each class, we only comptued the probabilyt of the <code class="docutils literal notranslate"><span class="pre">1</span></code> class.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">pt</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[9.99726525e-01, 2.73474984e-04]])
</pre></div>
</div>
</div>
</div>
<p>and we can see how it predicts on that point.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">pt</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0])
</pre></div>
</div>
</div>
</div>
<p>A single artificial neuron like the function below. where it has parameters
that have to be determined before we can use it on an input vector.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">aritificial_neuron_template</span><span class="p">(</span><span class="n">activation</span><span class="p">,</span><span class="n">weights</span><span class="p">,</span><span class="n">bias</span><span class="p">,</span><span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    simple artificial neuron</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    activation : function</span>
<span class="sd">        activation function of the neuron</span>
<span class="sd">    weights : numpy aray</span>
<span class="sd">        wights for summing inputs</span>
<span class="sd">    bias: numpy array</span>
<span class="sd">        bias term added to the weighted sum</span>
<span class="sd">    inputs : numpy array</span>
<span class="sd">        input to the neuron</span>

<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="n">activation</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="n">weights</span><span class="p">)</span> <span class="o">+</span><span class="n">bias</span><span class="p">)</span>

<span class="c1"># two common activation functions</span>
<span class="n">identity_activation</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span>
<span class="n">logistic_activation</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">expit</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>When we instantiate the multilyer perceptron object, <code class="docutils literal notranslate"><span class="pre">MLPClassifier</span></code>, we pick
the activation function and when we give data to the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method, we get
the weights and biases.</p>
<p>A neural network passes the data to the hidden layer, and the output of the
hidden layer to the output layer.  In our neural network, we have just one neuron
at each layer.</p>
<p>So the <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> method is the same as the following:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">logistic_activation</span><span class="p">,</span><span class="n">clf</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">clf</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                 <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">identity_activation</span><span class="p">,</span><span class="n">clf</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                   <span class="n">clf</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">pt</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.00027347]])
</pre></div>
</div>
</div>
</div>
<p>To make this easier to read, we can make the intermediate neurons their own
lambda functions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hidden_neuron</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">identity_activation</span><span class="p">,</span><span class="n">clf</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">clf</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>
<span class="n">output_neuron</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">expit</span><span class="p">,</span><span class="n">clf</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">clf</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>

<span class="n">output_neuron</span><span class="p">(</span><span class="n">hidden_neuron</span><span class="p">(</span><span class="n">pt</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.00027347]])
</pre></div>
</div>
</div>
</div>
<p>We can confirm that this works the same as the predict probability method:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">pt</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[9.99726525e-01, 2.73474984e-04]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="more-features-and-more-hidden-neurons">
<h2><span class="section-number">33.2. </span>More Features and More Hidden Neurons<a class="headerlink" href="#more-features-and-more-hidden-neurons" title="Permalink to this headline">#</a></h2>
<p>First, we’ll sample more features and then train a new classifier</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">pt_4d</span> <span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],[</span><span class="mf">1.5</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mf">.5</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">clf_4d</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span>
    <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
    <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;lbfgs&quot;</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">activation</span><span class="o">=</span> <span class="s1">&#39;identity&#39;</span>
<span class="p">)</span>

<span class="n">clf_4d</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>


<span class="n">clf_4d</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">Input In [19],</span> in <span class="ni">&lt;cell line: 2&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span>                                                     <span class="n">random_state</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">pt_4d</span> <span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],[</span><span class="mf">1.5</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mf">.5</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">clf_4d</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span>     <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span>     <span class="n">max_iter</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span>     <span class="n">activation</span><span class="o">=</span> <span class="s1">&#39;identity&#39;</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span> <span class="p">)</span>

<span class="ne">NameError</span>: name &#39;train_test_split&#39; is not defined
</pre></div>
</div>
</div>
</div>
<p>We can look at this data</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x0&#39;</span><span class="p">,</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span><span class="s1">&#39;x2&#39;</span><span class="p">,</span><span class="s1">&#39;x3&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="n">hue</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.PairGrid at 0x7f49d554acd0&gt;
</pre></div>
</div>
<img alt="../_images/2021-12-03_38_1.png" src="../_images/2021-12-03_38_1.png" />
</div>
</div>
<p>and based on this, we’ll pick a new pair of points to  test on:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pt_4d</span> <span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">],[</span><span class="mf">1.5</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">]])</span>
</pre></div>
</div>
</div>
</div>
<p>This neural network is just like the one before:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hidden_neuron_4d</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">identity_activation</span><span class="p">,</span>
                                                         <span class="n">clf_4d</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">clf_4d</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>
<span class="n">output_neuron_4d</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">logistic_activation</span><span class="p">,</span>
                                                         <span class="n">clf_4d</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">clf_4d</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>


<span class="n">output_neuron_4d</span><span class="p">(</span><span class="n">hidden_neuron_4d</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">Input In [22],</span> in <span class="ni">&lt;cell line: 7&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="n">hidden_neuron_4d</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">identity_activation</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span>                                                          <span class="n">clf_4d</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">clf_4d</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">output_neuron_4d</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">logistic_activation</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span>                                                          <span class="n">clf_4d</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">clf_4d</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">7</span> <span class="n">output_neuron_4d</span><span class="p">(</span><span class="n">hidden_neuron_4d</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">))</span>

<span class="nn">Input In [22],</span> in <span class="ni">&lt;lambda&gt;</span><span class="nt">(x)</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="n">hidden_neuron_4d</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">identity_activation</span><span class="p">,</span>
<span class="ne">----&gt; </span><span class="mi">2</span>                                                          <span class="n">clf_4d</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">clf_4d</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">output_neuron_4d</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">logistic_activation</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span>                                                          <span class="n">clf_4d</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">clf_4d</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="n">output_neuron_4d</span><span class="p">(</span><span class="n">hidden_neuron_4d</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">))</span>

<span class="ne">NameError</span>: name &#39;clf_4d&#39; is not defined
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf_4d</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">Input In [23],</span> in <span class="ni">&lt;cell line: 1&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">clf_4d</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;clf_4d&#39; is not defined
</pre></div>
</div>
</div>
</div>
<p>However, remember this one was not as accurate:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf_4d</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">Input In [24],</span> in <span class="ni">&lt;cell line: 1&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">clf_4d</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;clf_4d&#39; is not defined
</pre></div>
</div>
</div>
</div>
<p>To try imporving it, we will add more layers and a different activation function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf_4d_4h</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span>
    <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
    <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;lbfgs&quot;</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;logistic&#39;</span>
<span class="p">)</span>

<span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>


<span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RUNNING THE L-BFGS-B CODE

           * * *

Machine precision = 2.220D-16
 N =           17     M =           10

At X0         0 variables are exactly at the bounds

At iterate    0    f=  7.39798D-01    |proj g|=  7.60692D-02

At iterate    1    f=  7.26134D-01    |proj g|=  1.50172D-01

At iterate    2    f=  6.76306D-01    |proj g|=  5.00387D-02

At iterate    3    f=  6.49665D-01    |proj g|=  5.44130D-02

At iterate    4    f=  5.25451D-01    |proj g|=  2.15246D-01

At iterate    5    f=  4.23006D-01    |proj g|=  2.05051D-01

At iterate    6    f=  1.40544D-01    |proj g|=  4.57748D-02

At iterate    7    f=  1.28650D-01    |proj g|=  3.78602D-02

At iterate    8    f=  9.53885D-02    |proj g|=  1.72836D-02

At iterate    9    f=  8.44214D-02    |proj g|=  1.09155D-02

At iterate   10    f=  7.04328D-02    |proj g|=  9.14381D-03

At iterate   11    f=  6.48659D-02    |proj g|=  4.82831D-03

At iterate   12    f=  5.98470D-02    |proj g|=  8.90528D-03

At iterate   13    f=  5.28991D-02    |proj g|=  1.53860D-02

At iterate   14    f=  4.39896D-02    |proj g|=  4.77902D-03

At iterate   15    f=  4.25224D-02    |proj g|=  4.69741D-03

At iterate   16    f=  4.07994D-02    |proj g|=  2.21123D-03

At iterate   17    f=  3.95558D-02    |proj g|=  5.16637D-03

At iterate   18    f=  3.66907D-02    |proj g|=  1.92226D-03

At iterate   19    f=  3.48200D-02    |proj g|=  4.93243D-03

At iterate   20    f=  3.41086D-02    |proj g|=  3.44697D-03

At iterate   21    f=  3.36224D-02    |proj g|=  3.44515D-03

At iterate   22    f=  3.20026D-02    |proj g|=  1.72674D-03

At iterate   23    f=  3.14277D-02    |proj g|=  1.42370D-03

At iterate   24    f=  3.10135D-02    |proj g|=  6.81954D-04

At iterate   25    f=  3.09077D-02    |proj g|=  1.83127D-04

At iterate   26    f=  3.08484D-02    |proj g|=  3.98862D-04

At iterate   27    f=  3.07962D-02    |proj g|=  5.98374D-04

At iterate   28    f=  3.06875D-02    |proj g|=  7.19001D-04

At iterate   29    f=  3.06252D-02    |proj g|=  5.18501D-04

At iterate   30    f=  3.03507D-02    |proj g|=  9.92446D-04

At iterate   31    f=  2.94907D-02    |proj g|=  2.96420D-03

At iterate   32    f=  2.94497D-02    |proj g|=  2.94538D-03

At iterate   33    f=  2.93113D-02    |proj g|=  3.38284D-03

At iterate   34    f=  2.91957D-02    |proj g|=  2.96397D-03

At iterate   35    f=  2.90365D-02    |proj g|=  1.76136D-03

At iterate   36    f=  2.87991D-02    |proj g|=  2.46091D-04

At iterate   37    f=  2.87555D-02    |proj g|=  2.75138D-04

At iterate   38    f=  2.86773D-02    |proj g|=  4.07157D-04

At iterate   39    f=  2.84211D-02    |proj g|=  1.24944D-03

At iterate   40    f=  2.70889D-02    |proj g|=  2.96296D-03

At iterate   41    f=  2.67305D-02    |proj g|=  5.63750D-03

At iterate   42    f=  2.48073D-02    |proj g|=  2.81205D-03

At iterate   43    f=  2.35024D-02    |proj g|=  1.05261D-03

At iterate   44    f=  2.30253D-02    |proj g|=  6.67917D-04

At iterate   45    f=  2.29028D-02    |proj g|=  5.38500D-04

At iterate   46    f=  2.27677D-02    |proj g|=  8.60951D-04

At iterate   47    f=  2.25993D-02    |proj g|=  2.58897D-04

At iterate   48    f=  2.25169D-02    |proj g|=  2.80334D-04

At iterate   49    f=  2.23866D-02    |proj g|=  3.90709D-04

At iterate   50    f=  2.22414D-02    |proj g|=  3.80260D-04

At iterate   51    f=  2.18184D-02    |proj g|=  1.91141D-04

At iterate   52    f=  2.17625D-02    |proj g|=  2.42250D-04
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> This problem is unconstrained.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>At iterate   53    f=  2.16786D-02    |proj g|=  2.92993D-04

At iterate   54    f=  2.15285D-02    |proj g|=  2.69982D-04

At iterate   55    f=  2.15015D-02    |proj g|=  5.21127D-04

At iterate   56    f=  2.12361D-02    |proj g|=  4.07072D-04

At iterate   57    f=  2.12268D-02    |proj g|=  4.39523D-04

At iterate   58    f=  1.88186D-02    |proj g|=  2.90136D-03

At iterate   59    f=  1.88058D-02    |proj g|=  3.18867D-03

At iterate   60    f=  1.77612D-02    |proj g|=  3.47177D-03

At iterate   61    f=  1.54082D-02    |proj g|=  1.11205D-02

At iterate   62    f=  1.05133D-02    |proj g|=  2.26634D-03

At iterate   63    f=  9.48293D-03    |proj g|=  8.16960D-04

At iterate   64    f=  8.91869D-03    |proj g|=  1.20060D-03

At iterate   65    f=  8.61158D-03    |proj g|=  3.48433D-03

At iterate   66    f=  8.29355D-03    |proj g|=  5.15635D-04

At iterate   67    f=  8.23867D-03    |proj g|=  1.06216D-03

At iterate   68    f=  8.11866D-03    |proj g|=  1.65491D-03

At iterate   69    f=  7.94600D-03    |proj g|=  1.61213D-03

At iterate   70    f=  7.06812D-03    |proj g|=  7.92228D-04

At iterate   71    f=  6.51501D-03    |proj g|=  6.50439D-04

At iter
</pre></div>
</div>
</div>
</div>
<p>we see some improvment.</p>
<p>This network is more complicated. It has 5 total neurons:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hidden_neuron_4d_h0</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">logistic_activation</span><span class="p">,</span>
                                                         <span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span><span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>
<span class="n">hidden_neuron_4d_h1</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">logistic_activation</span><span class="p">,</span>
                                                         <span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span><span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>
<span class="n">hidden_neuron_4d_h2</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">logistic_activation</span><span class="p">,</span>
                                                         <span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">2</span><span class="p">],</span><span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>
<span class="n">hidden_neuron_4d_h3</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">logistic_activation</span><span class="p">,</span>
                                                         <span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">3</span><span class="p">],</span><span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">3</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>
<span class="n">output_neuron_4d_4h</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">logistic_activation</span><span class="p">,</span>
                                                         <span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ate   72    f=  5.81052D-03    |proj g|=  1.09789D-03

At iterate   73    f=  5.47472D-03    |proj g|=  1.59644D-03

At iterate   74    f=  5.38675D-03    |proj g|=  6.24687D-04

At iterate   75    f=  5.21617D-03    |proj g|=  1.71524D-03

At iterate   76    f=  5.03254D-03    |proj g|=  8.34665D-04

At iterate   77    f=  4.83337D-03    |proj g|=  5.96270D-04

At iterate   78    f=  4.63239D-03    |proj g|=  3.95691D-04

At iterate   79    f=  4.49875D-03    |proj g|=  2.84684D-04

At iterate   80    f=  4.33478D-03    |proj g|=  1.20827D-03

At iterate   81    f=  4.17861D-03    |proj g|=  4.13675D-04

At iterate   82    f=  3.97869D-03    |proj g|=  4.14723D-04

At iterate   83    f=  3.70626D-03    |proj g|=  8.83809D-04

At iterate   84    f=  3.67429D-03    |proj g|=  1.09986D-03

At iterate   85    f=  3.49290D-03    |proj g|=  1.77894D-04

At iterate   86    f=  3.45190D-03    |proj g|=  1.32719D-04

At iterate   87    f=  3.32256D-03    |proj g|=  2.79523D-04

At iterate   88    f=  3.19426D-03    |proj g|=  6.03583D-04

At iterate   89    f=  3.07239D-03    |proj g|=  6.20638D-04

At iterate   90    f=  3.04733D-03    |proj g|=  5.72891D-04

At iterate   91    f=  2.90220D-03    |proj g|=  5.43566D-04

At iterate   92    f=  2.82068D-03    |proj g|=  2.69010D-04

At iterate   93    f=  2.71584D-03    |proj g|=  1.79369D-04

At iterate   94    f=  2.54262D-03    |proj g|=  2.58689D-04

At iterate   95    f=  2.52792D-03    |proj g|=  6.65192D-04

At iterate   96    f=  2.41550D-03    |proj g|=  7.84073D-04

At iterate   97    f=  2.30862D-03    |proj g|=  1.05776D-04

At iterate   98    f=  2.28665D-03    |proj g|=  2.66785D-04

At iterate   99    f=  2.23598D-03    |proj g|=  1.91663D-04

At iterate  100    f=  2.20506D-03    |proj g|=  5.54797D-05

           * * *

Tit   = total number of iterations
Tnf   = total number of function evaluations
Tnint = total number of segments explored during Cauchy searches
Skip  = number of BFGS updates skipped
Nact  = number of active bounds at final generalized Cauchy point
Projg = norm of the final projected gradient
F     = final function value

           * * *

   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F
   17    100    146      1     0     0   5.548D-05   2.205D-03
  F =   2.2050631833495406E-003

CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_&lt;=_PGTOL            
</pre></div>
</div>
</div>
</div>
<p>And we have to take the output of all 4 hidden neurons into the output neuron,
because they are a single layer, not in sequence.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output_neuron_4d_4h</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">hidden_neuron_4d_h0</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">),</span>
                 <span class="n">hidden_neuron_4d_h1</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">),</span>
                 <span class="n">hidden_neuron_4d_h2</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">),</span>
                 <span class="n">hidden_neuron_4d_h3</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">)])</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ValueError</span><span class="g g-Whitespace">                                </span>Traceback (most recent call last)
<span class="nn">Input In [27],</span> in <span class="ni">&lt;cell line: 1&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">output_neuron_4d_4h</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">hidden_neuron_4d_h0</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">),</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span>                  <span class="n">hidden_neuron_4d_h1</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">),</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span>                  <span class="n">hidden_neuron_4d_h2</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">),</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span>                  <span class="n">hidden_neuron_4d_h3</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">)])</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

<span class="nn">Input In [26],</span> in <span class="ni">&lt;lambda&gt;</span><span class="nt">(x)</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">hidden_neuron_4d_h0</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">logistic_activation</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span>                                                          <span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span><span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">hidden_neuron_4d_h1</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">logistic_activation</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span>                                                          <span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span><span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">hidden_neuron_4d_h2</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">logistic_activation</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span>                                                          <span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">2</span><span class="p">],</span><span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>

<span class="nn">Input In [15],</span> in <span class="ni">aritificial_neuron_template</span><span class="nt">(activation, weights, bias, inputs)</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="k">def</span> <span class="nf">aritificial_neuron_template</span><span class="p">(</span><span class="n">activation</span><span class="p">,</span><span class="n">weights</span><span class="p">,</span><span class="n">bias</span><span class="p">,</span><span class="n">inputs</span><span class="p">):</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span>     <span class="sd">&#39;&#39;&#39;</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span><span class="sd">     simple artificial neuron</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span><span class="sd"> </span>
<span class="sd">   (...)</span>
<span class="g g-Whitespace">     </span><span class="mi">15</span><span class="sd"> </span>
<span class="g g-Whitespace">     </span><span class="mi">16</span><span class="sd">     &#39;&#39;&#39;</span>
<span class="ne">---&gt; </span><span class="mi">17</span>     <span class="k">return</span> <span class="n">activation</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="n">weights</span><span class="p">)</span> <span class="o">+</span><span class="n">bias</span><span class="p">)</span>

<span class="nn">ValueError: matmul: Input operand 1 has a mismatch</span> in <span class="ni">its core dimension 0, with gufunc signature (n?,k),(k,m?)-&gt;(n?,m?) </span><span class="nt">(size 2 is different from 4)</span>
</pre></div>
</div>
</div>
</div>
<p>And again, we see this is the probability of predicting 1:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ValueError</span><span class="g g-Whitespace">                                </span>Traceback (most recent call last)
<span class="nn">Input In [28],</span> in <span class="ni">&lt;cell line: 1&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.8.13/x64/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1252,</span> in <span class="ni">MLPClassifier.predict_proba</span><span class="nt">(self, X)</span>
<span class="g g-Whitespace">   </span><span class="mi">1238</span> <span class="sd">&quot;&quot;&quot;Probability estimates.</span>
<span class="g g-Whitespace">   </span><span class="mi">1239</span><span class="sd"> </span>
<span class="g g-Whitespace">   </span><span class="mi">1240</span><span class="sd"> Parameters</span>
<span class="sd">   (...)</span>
<span class="g g-Whitespace">   </span><span class="mi">1249</span><span class="sd">     model, where classes are ordered as they are in `self.classes_`.</span>
<span class="g g-Whitespace">   </span><span class="mi">1250</span><span class="sd"> &quot;&quot;&quot;</span>
<span class="g g-Whitespace">   </span><span class="mi">1251</span> <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1252</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pass_fast</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1254</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs_</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1255</span>     <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.8.13/x64/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:160,</span> in <span class="ni">BaseMultilayerPerceptron._forward_pass_fast</span><span class="nt">(self, X)</span>
<span class="g g-Whitespace">    </span><span class="mi">144</span> <span class="k">def</span> <span class="nf">_forward_pass_fast</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">145</span>     <span class="sd">&quot;&quot;&quot;Predict using the trained model</span>
<span class="g g-Whitespace">    </span><span class="mi">146</span><span class="sd"> </span>
<span class="g g-Whitespace">    </span><span class="mi">147</span><span class="sd">     This is the same as _forward_pass but does not record the activations</span>
<span class="sd">   (...)</span>
<span class="g g-Whitespace">    </span><span class="mi">158</span><span class="sd">         The decision function of the samples for each class in the model.</span>
<span class="g g-Whitespace">    </span><span class="mi">159</span><span class="sd">     &quot;&quot;&quot;</span>
<span class="ne">--&gt; </span><span class="mi">160</span>     <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;csr&quot;</span><span class="p">,</span> <span class="s2">&quot;csc&quot;</span><span class="p">],</span> <span class="n">reset</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">162</span>     <span class="c1"># Initialize first layer</span>
<span class="g g-Whitespace">    </span><span class="mi">163</span>     <span class="n">activation</span> <span class="o">=</span> <span class="n">X</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.8.13/x64/lib/python3.8/site-packages/sklearn/base.py:600,</span> in <span class="ni">BaseEstimator._validate_data</span><span class="nt">(self, X, y, reset, validate_separately, **check_params)</span>
<span class="g g-Whitespace">    </span><span class="mi">597</span>     <span class="n">out</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
<span class="g g-Whitespace">    </span><span class="mi">599</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">no_val_X</span> <span class="ow">and</span> <span class="n">check_params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ensure_2d&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">600</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_check_n_features</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">reset</span><span class="o">=</span><span class="n">reset</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">602</span> <span class="k">return</span> <span class="n">out</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.8.13/x64/lib/python3.8/site-packages/sklearn/base.py:400,</span> in <span class="ni">BaseEstimator._check_n_features</span><span class="nt">(self, X, reset)</span>
<span class="g g-Whitespace">    </span><span class="mi">397</span>     <span class="k">return</span>
<span class="g g-Whitespace">    </span><span class="mi">399</span> <span class="k">if</span> <span class="n">n_features</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">400</span>     <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">401</span>         <span class="sa">f</span><span class="s2">&quot;X has </span><span class="si">{</span><span class="n">n_features</span><span class="si">}</span><span class="s2"> features, but </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> &quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">402</span>         <span class="sa">f</span><span class="s2">&quot;is expecting </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span><span class="si">}</span><span class="s2"> features as input.&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">403</span>     <span class="p">)</span>

<span class="ne">ValueError</span>: X has 4 features, but MLPClassifier is expecting 2 features as input.
</pre></div>
</div>
</div>
</div>
<!-- ```{code-cell} ipython3
clf = MLPClassifier(
  hidden_layer_sizes=(1),
  max_iter=100,
  alpha=1e-4,
  solver="lbfgs",
  verbose=10,
  activation= 'logistic'
)
clf.fit(X_train, y_train)

clf.score(X_test, y_test)
``` -->
</section>
<section id="optional-what-is-a-numerical-optimiztion-algorithm">
<h2><span class="section-number">33.3. </span>(optional) What is a numerical optimiztion algorithm?<a class="headerlink" href="#optional-what-is-a-numerical-optimiztion-algorithm" title="Permalink to this headline">#</a></h2>
<p>Numerical Optimization algorithms are at the core of many of the fit methods.</p>
<p>One way we can optimize a function is to take the derivative, set it equal to
zero and sovle for the parameter.  If we know the funciton is convex (like a
bowl or valley shape) then the place where the derivative (slope) is 0 is
the bottom or lowest point of the valley.</p>
<p>Numerial optimzaiton is for when we can’t analytically solve that problem once
we set it equal to zero. Optimizaiton algorithms are sort of like search algorithms
but can work in high dimensions and use strategy based on calculus.</p>
<p>The basic idea in many numerical optimization algorithms is to start at a point
(initial setting of the coefficients in this case) and then compute the value
of the function then change the coefficients a little and compute again. We can
use those two point to see if the direction we “moved” or the way we changed the
parameters made it better or worse. If it was better, we change them more in the
same direction, (if we made both smaller then we make them both smaller again)
if it got worse, we change in a different direction.</p>
<p>You can think of this like trying to find the bottom of a valley, without being
able to see, just check your altitude. You take a step left, right, forward or
back and then see if your altitude went up or down.</p>
<p>LBGFS acutally uses the derivative, so it’s like you can see the direction of
the hill you’re on, but you have to keep taking steps and then if you reacha point
where you can’t go down anymore you know you are done.  When the algorithm
finds it can’t get better, that’s called convergence.</p>
<p>Stochastic gradient descent works in high dimensions where it’s too hard to
do the derivative, but you can randomly move in different directions (or take
the partial derivate in a small numbe rof defintions). Adam is a specical version fo that with better strategy.</p>
<p>Numerical optimization is a whole research area.  In graduate school, I took a
whole semester long course just learning different algorithms for this.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="2021-12-01.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">32. </span>Neural Networks</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="2021-12-06.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">34. </span>Review, IDEA, &amp; Preparing for Deep Learning</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Professor Sarah M Brown<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>